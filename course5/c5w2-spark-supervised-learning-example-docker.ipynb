{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Spark Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.5\n",
      "('spark.app.id', 'local-1588997578209')\n",
      "('spark.app.name', 'spark')\n",
      "('spark.driver.port', '33067')\n",
      "('spark.rdd.compress', 'True')\n",
      "('spark.serializer.objectStreamReset', '100')\n",
      "('spark.master', 'local[*]')\n",
      "('spark.executor.id', 'driver')\n",
      "('spark.submit.deployMode', 'client')\n",
      "('spark.driver.host', '41e01baad259')\n",
      "('spark.ui.showConsoleProgress', 'true')\n"
     ]
    }
   ],
   "source": [
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "# Create Spark config for local cluster manager\n",
    "sparkConf = SparkConf()\n",
    "sparkConf.setAppName(\"spark\")\n",
    "sparkConf.setMaster(\"local[*]\")\n",
    "\n",
    "# Initialize our Spark cluster, this will actually\n",
    "# generate the worker nodes.\n",
    "spark = SparkSession.builder.config(conf=sparkConf).getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "\n",
    "\n",
    "print(spark.version)\n",
    "\n",
    "for attribute in sc._conf.getAll():\n",
    "    print(attribute)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Sample Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-05-08 13:00:36--  https://raw.githubusercontent.com/apache/spark/master/data/mllib/sample_libsvm_data.txt\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.64.133, 151.101.0.133, 151.101.192.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.64.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 104736 (102K) [text/plain]\n",
      "Saving to: ‘sample_libsvm_data.txt’\n",
      "\n",
      "sample_libsvm_data. 100%[===================>] 102.28K  --.-KB/s    in 0.03s   \n",
      "\n",
      "2020-05-08 13:00:37 (3.67 MB/s) - ‘sample_libsvm_data.txt’ saved [104736/104736]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/apache/spark/master/data/mllib/sample_libsvm_data.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['spark-intro.pdf',\n",
       " 'calculate-pi-out.txt',\n",
       " 'docker-tutorial',\n",
       " 'c5w1-spark-intro.ipynb',\n",
       " '.local',\n",
       " 'sherlock-holmes.txt',\n",
       " 'c5w1-docker-tutorial.ipynb',\n",
       " 'c5w2-spark-mllib-example-docker.ipynb',\n",
       " 'sample_libsvm_data.txt',\n",
       " '.ipython',\n",
       " 'calculate-pi.py',\n",
       " '.python-version',\n",
       " '.ipynb_checkpoints',\n",
       " 'c5w2-spark-mllib-example.ipynb',\n",
       " '.bash_history']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.feature import IndexToString, StringIndexer, VectorIndexer\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and parse the data file, converting it to a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = spark.read.format(\"libsvm\").load(\"./sample_libsvm_data.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 100 records with 2 columns\n",
      "\n",
      "\n",
      "+-----+--------------------+\n",
      "|label|            features|\n",
      "+-----+--------------------+\n",
      "|  0.0|(692,[127,128,129...|\n",
      "|  1.0|(692,[158,159,160...|\n",
      "|  1.0|(692,[124,125,126...|\n",
      "|  1.0|(692,[152,153,154...|\n",
      "|  1.0|(692,[151,152,153...|\n",
      "|  0.0|(692,[129,130,131...|\n",
      "|  1.0|(692,[158,159,160...|\n",
      "|  1.0|(692,[99,100,101,...|\n",
      "|  0.0|(692,[154,155,156...|\n",
      "|  0.0|(692,[127,128,129...|\n",
      "|  1.0|(692,[154,155,156...|\n",
      "|  0.0|(692,[153,154,155...|\n",
      "|  0.0|(692,[151,152,153...|\n",
      "|  1.0|(692,[129,130,131...|\n",
      "|  0.0|(692,[154,155,156...|\n",
      "|  1.0|(692,[150,151,152...|\n",
      "|  0.0|(692,[124,125,126...|\n",
      "|  0.0|(692,[152,153,154...|\n",
      "|  1.0|(692,[97,98,99,12...|\n",
      "|  1.0|(692,[124,125,126...|\n",
      "+-----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(f'Read {data.count()} records with {len(data.columns)} columns\\n\\n')\n",
    "print(data.show())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(label=0.0, features=SparseVector(692, {127: 51.0, 128: 159.0, 129: 253.0, 130: 159.0, 131: 50.0, 154: 48.0, 155: 238.0, 156: 252.0, 157: 252.0, 158: 252.0, 159: 237.0, 181: 54.0, 182: 227.0, 183: 253.0, 184: 252.0, 185: 239.0, 186: 233.0, 187: 252.0, 188: 57.0, 189: 6.0, 207: 10.0, 208: 60.0, 209: 224.0, 210: 252.0, 211: 253.0, 212: 252.0, 213: 202.0, 214: 84.0, 215: 252.0, 216: 253.0, 217: 122.0, 235: 163.0, 236: 252.0, 237: 252.0, 238: 252.0, 239: 253.0, 240: 252.0, 241: 252.0, 242: 96.0, 243: 189.0, 244: 253.0, 245: 167.0, 262: 51.0, 263: 238.0, 264: 253.0, 265: 253.0, 266: 190.0, 267: 114.0, 268: 253.0, 269: 228.0, 270: 47.0, 271: 79.0, 272: 255.0, 273: 168.0, 289: 48.0, 290: 238.0, 291: 252.0, 292: 252.0, 293: 179.0, 294: 12.0, 295: 75.0, 296: 121.0, 297: 21.0, 300: 253.0, 301: 243.0, 302: 50.0, 316: 38.0, 317: 165.0, 318: 253.0, 319: 233.0, 320: 208.0, 321: 84.0, 328: 253.0, 329: 252.0, 330: 165.0, 343: 7.0, 344: 178.0, 345: 252.0, 346: 240.0, 347: 71.0, 348: 19.0, 349: 28.0, 356: 253.0, 357: 252.0, 358: 195.0, 371: 57.0, 372: 252.0, 373: 252.0, 374: 63.0, 384: 253.0, 385: 252.0, 386: 195.0, 399: 198.0, 400: 253.0, 401: 190.0, 412: 255.0, 413: 253.0, 414: 196.0, 426: 76.0, 427: 246.0, 428: 252.0, 429: 112.0, 440: 253.0, 441: 252.0, 442: 148.0, 454: 85.0, 455: 252.0, 456: 230.0, 457: 25.0, 466: 7.0, 467: 135.0, 468: 253.0, 469: 186.0, 470: 12.0, 482: 85.0, 483: 252.0, 484: 223.0, 493: 7.0, 494: 131.0, 495: 252.0, 496: 225.0, 497: 71.0, 510: 85.0, 511: 252.0, 512: 145.0, 520: 48.0, 521: 165.0, 522: 252.0, 523: 173.0, 538: 86.0, 539: 253.0, 540: 225.0, 547: 114.0, 548: 238.0, 549: 253.0, 550: 162.0, 566: 85.0, 567: 252.0, 568: 249.0, 569: 146.0, 570: 48.0, 571: 29.0, 572: 85.0, 573: 178.0, 574: 225.0, 575: 253.0, 576: 223.0, 577: 167.0, 578: 56.0, 594: 85.0, 595: 252.0, 596: 252.0, 597: 252.0, 598: 229.0, 599: 215.0, 600: 252.0, 601: 252.0, 602: 252.0, 603: 196.0, 604: 130.0, 622: 28.0, 623: 199.0, 624: 252.0, 625: 252.0, 626: 253.0, 627: 252.0, 628: 252.0, 629: 233.0, 630: 145.0, 651: 25.0, 652: 128.0, 653: 252.0, 654: 253.0, 655: 252.0, 656: 141.0, 657: 37.0}))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.first()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Index labels, adding metadata to the label column.\n",
    "### Fit on whole dataset to include all labels in index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelIndexer = StringIndexer(inputCol=\"label\", outputCol=\"indexedLabel\").fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+------------+\n",
      "|label|            features|indexedLabel|\n",
      "+-----+--------------------+------------+\n",
      "|  0.0|(692,[127,128,129...|         1.0|\n",
      "|  1.0|(692,[158,159,160...|         0.0|\n",
      "|  1.0|(692,[124,125,126...|         0.0|\n",
      "|  1.0|(692,[152,153,154...|         0.0|\n",
      "|  1.0|(692,[151,152,153...|         0.0|\n",
      "|  0.0|(692,[129,130,131...|         1.0|\n",
      "|  1.0|(692,[158,159,160...|         0.0|\n",
      "|  1.0|(692,[99,100,101,...|         0.0|\n",
      "|  0.0|(692,[154,155,156...|         1.0|\n",
      "|  0.0|(692,[127,128,129...|         1.0|\n",
      "|  1.0|(692,[154,155,156...|         0.0|\n",
      "|  0.0|(692,[153,154,155...|         1.0|\n",
      "|  0.0|(692,[151,152,153...|         1.0|\n",
      "|  1.0|(692,[129,130,131...|         0.0|\n",
      "|  0.0|(692,[154,155,156...|         1.0|\n",
      "|  1.0|(692,[150,151,152...|         0.0|\n",
      "|  0.0|(692,[124,125,126...|         1.0|\n",
      "|  0.0|(692,[152,153,154...|         1.0|\n",
      "|  1.0|(692,[97,98,99,12...|         0.0|\n",
      "|  1.0|(692,[124,125,126...|         0.0|\n",
      "+-----+--------------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "labelIndexer.transform(data).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`StringIndexer` converts a string column to a numerical index column that will be treated as a categorical variable by by spark.\n",
    "\n",
    "NOTE: In this case we're basically one-hot encoding the label column. Seems silly to do it like this since label column is already one-hot encoded, but doing otherwise left as exercise..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automatically identify categorical features, and index them.\n",
    "### Set maxCategories so features with > 4 distinct values are treated as continuous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "featureIndexer =\\\n",
    "    VectorIndexer(inputCol=\"features\", outputCol=\"indexedFeatures\", maxCategories=4).fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------+\n",
      "|label|            features|     indexedFeatures|\n",
      "+-----+--------------------+--------------------+\n",
      "|  0.0|(692,[127,128,129...|(692,[127,128,129...|\n",
      "|  1.0|(692,[158,159,160...|(692,[158,159,160...|\n",
      "|  1.0|(692,[124,125,126...|(692,[124,125,126...|\n",
      "|  1.0|(692,[152,153,154...|(692,[152,153,154...|\n",
      "|  1.0|(692,[151,152,153...|(692,[151,152,153...|\n",
      "|  0.0|(692,[129,130,131...|(692,[129,130,131...|\n",
      "|  1.0|(692,[158,159,160...|(692,[158,159,160...|\n",
      "|  1.0|(692,[99,100,101,...|(692,[99,100,101,...|\n",
      "|  0.0|(692,[154,155,156...|(692,[154,155,156...|\n",
      "|  0.0|(692,[127,128,129...|(692,[127,128,129...|\n",
      "|  1.0|(692,[154,155,156...|(692,[154,155,156...|\n",
      "|  0.0|(692,[153,154,155...|(692,[153,154,155...|\n",
      "|  0.0|(692,[151,152,153...|(692,[151,152,153...|\n",
      "|  1.0|(692,[129,130,131...|(692,[129,130,131...|\n",
      "|  0.0|(692,[154,155,156...|(692,[154,155,156...|\n",
      "|  1.0|(692,[150,151,152...|(692,[150,151,152...|\n",
      "|  0.0|(692,[124,125,126...|(692,[124,125,126...|\n",
      "|  0.0|(692,[152,153,154...|(692,[152,153,154...|\n",
      "|  1.0|(692,[97,98,99,12...|(692,[97,98,99,12...|\n",
      "|  1.0|(692,[124,125,126...|(692,[124,125,126...|\n",
      "+-----+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "featureIndexer.transform(data).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`VectorIndexer` helps process a dataset of unknown vectors into a dataset with some continuous features and some categorical features by automatically identifying categorical features. The choice between continuous and categorical is based upon the maxCategories parameter.\n",
    "\n",
    "https://spark.apache.org/docs/latest/ml-features.html#vectorindexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chose 315 categorical features: 645, 69, 365, 138, 479, 333, 249, 0, 666, 88, 170, 115, 276, 308, 5, 449, 120, 614, 677, 202, 10, 56, 533, 142, 340, 670, 174, 42, 417, 24, 37, 25, 257, 389, 52, 14, 504, 110, 587, 619, 196, 559, 638, 20, 421, 46, 93, 284, 228, 448, 57, 78, 29, 475, 164, 591, 646, 253, 106, 121, 84, 147, 280, 61, 221, 396, 89, 133, 116, 1, 507, 312, 74, 307, 452, 6, 248, 60, 117, 678, 529, 85, 201, 220, 366, 534, 102, 334, 28, 38, 561, 392, 70, 424, 192, 21, 137, 165, 33, 92, 229, 252, 197, 361, 65, 97, 665, 224, 615, 9, 53, 169, 141, 420, 109, 256, 225, 339, 77, 193, 669, 476, 642, 590, 679, 96, 393, 647, 173, 13, 41, 503, 134, 73, 105, 2, 311, 558, 674, 530, 586, 618, 166, 32, 34, 148, 45, 279, 64, 17, 584, 562, 423, 191, 22, 44, 59, 118, 281, 27, 641, 71, 391, 12, 445, 54, 611, 144, 49, 335, 86, 672, 172, 113, 219, 419, 81, 362, 451, 76, 7, 39, 649, 98, 616, 477, 367, 535, 103, 140, 621, 91, 66, 251, 668, 198, 108, 278, 223, 394, 306, 135, 563, 226, 3, 505, 80, 167, 35, 473, 675, 589, 531, 255, 648, 112, 617, 194, 145, 48, 557, 63, 640, 18, 282, 95, 310, 50, 67, 199, 673, 16, 585, 502, 338, 643, 31, 336, 613, 11, 72, 446, 612, 143, 43, 250, 450, 99, 363, 87, 671, 104, 368, 588, 40, 26, 390, 55, 114, 171, 139, 418, 23, 8, 75, 119, 58, 667, 478, 82, 620, 447, 36, 168, 146, 30, 51, 19, 422, 564, 305, 107, 4, 136, 506, 79, 195, 474, 532, 94, 283, 395, 644, 47, 15, 163, 200, 68, 62, 277, 691, 501, 90, 111, 254, 227, 337, 83, 309, 560, 639, 676, 222, 592, 364\n"
     ]
    }
   ],
   "source": [
    "categoricalFeatures = featureIndexer.categoryMaps\n",
    "\n",
    "print(\"Chose %d categorical features: %s\" %\n",
    "      (len(categoricalFeatures), \", \".join(str(k) for k in categoricalFeatures.keys())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the data into training and test sets (30% held out for testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "(trainingData, testData) = data.randomSplit([0.7, 0.3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a RandomForest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(labelCol=\"indexedLabel\", featuresCol=\"indexedFeatures\", numTrees=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert indexed labels back to original labels.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelConverter = IndexToString(inputCol=\"prediction\", outputCol=\"predictedLabel\",\n",
    "                               labels=labelIndexer.labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`IndexToString` maps a column of label indices back to a column containing the original labels as strings. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build and pipeline and fit on training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chain indexers and forest in a Pipeline\n",
    "pipeline = Pipeline(stages=[labelIndexer, featureIndexer, rf, labelConverter])\n",
    "\n",
    "# Train model.  This also runs the indexers.\n",
    "model = pipeline.fit(trainingData)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make predictions on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.transform(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+------------+--------------------+-------------+-----------+----------+--------------+\n",
      "|label|            features|indexedLabel|     indexedFeatures|rawPrediction|probability|prediction|predictedLabel|\n",
      "+-----+--------------------+------------+--------------------+-------------+-----------+----------+--------------+\n",
      "|  0.0|(692,[100,101,102...|         1.0|(692,[100,101,102...|    [1.0,9.0]|  [0.1,0.9]|       1.0|           0.0|\n",
      "|  0.0|(692,[122,123,124...|         1.0|(692,[122,123,124...|   [0.0,10.0]|  [0.0,1.0]|       1.0|           0.0|\n",
      "|  0.0|(692,[123,124,125...|         1.0|(692,[123,124,125...|   [0.0,10.0]|  [0.0,1.0]|       1.0|           0.0|\n",
      "|  0.0|(692,[123,124,125...|         1.0|(692,[123,124,125...|    [1.0,9.0]|  [0.1,0.9]|       1.0|           0.0|\n",
      "|  0.0|(692,[124,125,126...|         1.0|(692,[124,125,126...|   [0.0,10.0]|  [0.0,1.0]|       1.0|           0.0|\n",
      "|  0.0|(692,[124,125,126...|         1.0|(692,[124,125,126...|    [1.0,9.0]|  [0.1,0.9]|       1.0|           0.0|\n",
      "|  0.0|(692,[125,126,127...|         1.0|(692,[125,126,127...|   [0.0,10.0]|  [0.0,1.0]|       1.0|           0.0|\n",
      "|  0.0|(692,[126,127,128...|         1.0|(692,[126,127,128...|   [0.0,10.0]|  [0.0,1.0]|       1.0|           0.0|\n",
      "|  0.0|(692,[126,127,128...|         1.0|(692,[126,127,128...|   [0.0,10.0]|  [0.0,1.0]|       1.0|           0.0|\n",
      "|  0.0|(692,[129,130,131...|         1.0|(692,[129,130,131...|    [1.0,9.0]|  [0.1,0.9]|       1.0|           0.0|\n",
      "|  0.0|(692,[152,153,154...|         1.0|(692,[152,153,154...|    [1.0,9.0]|  [0.1,0.9]|       1.0|           0.0|\n",
      "|  0.0|(692,[153,154,155...|         1.0|(692,[153,154,155...|   [0.0,10.0]|  [0.0,1.0]|       1.0|           0.0|\n",
      "|  0.0|(692,[154,155,156...|         1.0|(692,[154,155,156...|   [0.0,10.0]|  [0.0,1.0]|       1.0|           0.0|\n",
      "|  1.0|(692,[97,98,99,12...|         0.0|(692,[97,98,99,12...|    [9.0,1.0]|  [0.9,0.1]|       0.0|           1.0|\n",
      "|  1.0|(692,[124,125,126...|         0.0|(692,[124,125,126...|    [6.0,4.0]|  [0.6,0.4]|       0.0|           1.0|\n",
      "|  1.0|(692,[124,125,126...|         0.0|(692,[124,125,126...|    [8.0,2.0]|  [0.8,0.2]|       0.0|           1.0|\n",
      "|  1.0|(692,[124,125,126...|         0.0|(692,[124,125,126...|   [10.0,0.0]|  [1.0,0.0]|       0.0|           1.0|\n",
      "|  1.0|(692,[125,126,153...|         0.0|(692,[125,126,153...|    [9.0,1.0]|  [0.9,0.1]|       0.0|           1.0|\n",
      "|  1.0|(692,[127,128,129...|         0.0|(692,[127,128,129...|   [10.0,0.0]|  [1.0,0.0]|       0.0|           1.0|\n",
      "|  1.0|(692,[128,129,130...|         0.0|(692,[128,129,130...|   [10.0,0.0]|  [1.0,0.0]|       0.0|           1.0|\n",
      "+-----+--------------------+------------+--------------------+-------------+-----------+----------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display model metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-----+--------------------+\n",
      "|predictedLabel|label|            features|\n",
      "+--------------+-----+--------------------+\n",
      "|           0.0|  0.0|(692,[122,123,124...|\n",
      "|           0.0|  0.0|(692,[124,125,126...|\n",
      "|           0.0|  0.0|(692,[126,127,128...|\n",
      "|           0.0|  0.0|(692,[126,127,128...|\n",
      "|           0.0|  0.0|(692,[126,127,128...|\n",
      "+--------------+-----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Test Error = 0.0357143\n",
      "RandomForestClassificationModel (uid=RandomForestClassifier_4d9dcf212846) with 2 trees\n"
     ]
    }
   ],
   "source": [
    "# Select example rows to display.\n",
    "predictions.select(\"predictedLabel\", \"label\", \"features\").show(5)\n",
    "\n",
    "# Select (prediction, true label) and compute test error\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"indexedLabel\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "\n",
    "print(\"Test Error = %g\" % (1.0 - accuracy))\n",
    "\n",
    "rfModel = model.stages[2]\n",
    "print(rfModel)  # summary only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+------------+--------------------+-------------+-----------+----------+--------------+\n",
      "|label|            features|indexedLabel|     indexedFeatures|rawPrediction|probability|prediction|predictedLabel|\n",
      "+-----+--------------------+------------+--------------------+-------------+-----------+----------+--------------+\n",
      "|  0.0|(692,[100,101,102...|         1.0|(692,[100,101,102...|    [1.0,9.0]|  [0.1,0.9]|       1.0|           0.0|\n",
      "|  0.0|(692,[122,123,124...|         1.0|(692,[122,123,124...|   [0.0,10.0]|  [0.0,1.0]|       1.0|           0.0|\n",
      "|  0.0|(692,[123,124,125...|         1.0|(692,[123,124,125...|   [0.0,10.0]|  [0.0,1.0]|       1.0|           0.0|\n",
      "|  0.0|(692,[123,124,125...|         1.0|(692,[123,124,125...|    [1.0,9.0]|  [0.1,0.9]|       1.0|           0.0|\n",
      "|  0.0|(692,[124,125,126...|         1.0|(692,[124,125,126...|   [0.0,10.0]|  [0.0,1.0]|       1.0|           0.0|\n",
      "|  0.0|(692,[124,125,126...|         1.0|(692,[124,125,126...|    [1.0,9.0]|  [0.1,0.9]|       1.0|           0.0|\n",
      "|  0.0|(692,[125,126,127...|         1.0|(692,[125,126,127...|   [0.0,10.0]|  [0.0,1.0]|       1.0|           0.0|\n",
      "|  0.0|(692,[126,127,128...|         1.0|(692,[126,127,128...|   [0.0,10.0]|  [0.0,1.0]|       1.0|           0.0|\n",
      "|  0.0|(692,[126,127,128...|         1.0|(692,[126,127,128...|   [0.0,10.0]|  [0.0,1.0]|       1.0|           0.0|\n",
      "|  0.0|(692,[129,130,131...|         1.0|(692,[129,130,131...|    [1.0,9.0]|  [0.1,0.9]|       1.0|           0.0|\n",
      "|  0.0|(692,[152,153,154...|         1.0|(692,[152,153,154...|    [1.0,9.0]|  [0.1,0.9]|       1.0|           0.0|\n",
      "|  0.0|(692,[153,154,155...|         1.0|(692,[153,154,155...|   [0.0,10.0]|  [0.0,1.0]|       1.0|           0.0|\n",
      "|  0.0|(692,[154,155,156...|         1.0|(692,[154,155,156...|   [0.0,10.0]|  [0.0,1.0]|       1.0|           0.0|\n",
      "|  1.0|(692,[97,98,99,12...|         0.0|(692,[97,98,99,12...|    [9.0,1.0]|  [0.9,0.1]|       0.0|           1.0|\n",
      "|  1.0|(692,[124,125,126...|         0.0|(692,[124,125,126...|    [6.0,4.0]|  [0.6,0.4]|       0.0|           1.0|\n",
      "|  1.0|(692,[124,125,126...|         0.0|(692,[124,125,126...|    [8.0,2.0]|  [0.8,0.2]|       0.0|           1.0|\n",
      "|  1.0|(692,[124,125,126...|         0.0|(692,[124,125,126...|   [10.0,0.0]|  [1.0,0.0]|       0.0|           1.0|\n",
      "|  1.0|(692,[125,126,153...|         0.0|(692,[125,126,153...|    [9.0,1.0]|  [0.9,0.1]|       0.0|           1.0|\n",
      "|  1.0|(692,[127,128,129...|         0.0|(692,[127,128,129...|   [10.0,0.0]|  [1.0,0.0]|       0.0|           1.0|\n",
      "|  1.0|(692,[128,129,130...|         0.0|(692,[128,129,130...|   [10.0,0.0]|  [1.0,0.0]|       0.0|           1.0|\n",
      "+-----+--------------------+------------+--------------------+-------------+-----------+----------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
